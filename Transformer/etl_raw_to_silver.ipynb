{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76535204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üáßüá∑ Iniciando o processo ETL (Raw -> Silver) - Acidentes A√©reos...\n",
      "üìÇ Buscando arquivo de dados brutos...\n",
      "   -> Lendo Arquivo: ..\\Data_Layer\\raw\\data_raw.csv...\n",
      "‚úÖ Carga Raw Completa! Registros carregados: 6114\n",
      "üõ†Ô∏è Iniciando a limpeza, padroniza√ß√£o e remo√ß√£o de nulos...\n",
      "   -> Processando datas...\n",
      "   -> Corrigindo Lat/Lon cient√≠fica...\n",
      "   -> Convertendo n√∫meros...\n",
      "‚ú® Transforma√ß√£o conclu√≠da! Base Silver Final: 6114 registros.\n",
      "\n",
      "üîå Conectando ao Banco de Dados...\n",
      "‚ö†Ô∏è Falha ao conectar em 'db'. Tentando 'localhost' (caso esteja rodando localmente)...\n",
      "‚úÖ Conectado via Localhost!\n",
      "üìú Verificando DDL...\n",
      "üíæ Inserindo 6114 registros na tabela 'public.acd'...\n",
      "‚úÖ SUCESSO! Dados carregados na tabela 'public.acd'.\n",
      "\n",
      "üöÄ Job ETL finalizado em 7.00 segundos!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CONFIGURA√á√ÉO E IN√çCIO\n",
    "# ==============================================================================\n",
    "print(\"üáßüá∑ Iniciando o processo ETL (Raw -> Silver) - Acidentes A√©reos...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Fun√ß√£o auxiliar para encontrar arquivos\n",
    "def encontrar_arquivo(nome_arquivo):\n",
    "    possible_paths = [\n",
    "        nome_arquivo,\n",
    "        os.path.join('Data_Layer', 'raw', nome_arquivo),\n",
    "        os.path.join('raw', nome_arquivo),\n",
    "        os.path.join('..', 'Data_Layer', 'raw', nome_arquivo),\n",
    "        # Caminho absoluto interno do Docker\n",
    "        rf\"/home/jovyan/work/Data_Layer/raw/{nome_arquivo}\" \n",
    "    ]\n",
    "    \n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. EXTRA√á√ÉO (EXTRACTION)\n",
    "# ==============================================================================\n",
    "print(\"üìÇ Buscando arquivo de dados brutos...\")\n",
    "\n",
    "nome_arquivo_raw = 'data_raw.csv'\n",
    "path_raw = encontrar_arquivo(nome_arquivo_raw)\n",
    "\n",
    "if not path_raw:\n",
    "    print(f\"‚ùå [ERRO CR√çTICO] Arquivo '{nome_arquivo_raw}' n√£o encontrado.\")\n",
    "    exit(1)\n",
    "\n",
    "try:\n",
    "    print(f\"   -> Lendo Arquivo: {path_raw}...\")\n",
    "    # Lendo com sep=';' e encoding latin1\n",
    "    df = pd.read_csv(path_raw, sep=';', encoding='latin1', dtype=str)\n",
    "    \n",
    "    print(f\"‚úÖ Carga Raw Completa! Registros carregados: {len(df)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao ler CSV: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. TRANSFORMA√á√ÉO (TRANSFORMATION)\n",
    "# ==============================================================================\n",
    "print(\"üõ†Ô∏è Iniciando a limpeza, padroniza√ß√£o e remo√ß√£o de nulos...\")\n",
    "df_silver = df.copy()\n",
    "\n",
    "# --- 3.1 RENOMEA√á√ÉO (Mapeamento Raw -> SQL Schema) ---\n",
    "mapa_colunas = {\n",
    "    'Codigo da Ocorrencia': 'cod_ocr',\n",
    "    'Classificacao da Ocorrencia ': 'cls_ocr',\n",
    "    'Classificacao da Ocorrencia': 'cls_ocr',\n",
    "    'Data e Hora da Ocorrencia': 'dta_ocr',\n",
    "    'Latitude da Ocorrencia': 'lat',\n",
    "    'Longitude da Ocorrencia': 'lon',\n",
    "    'Cidade da Ocorrencia': 'mun',\n",
    "    'UF da Ocorrencia': 'uf',\n",
    "    'Aerodromo da Ocorrencia': 'aer_ocr',\n",
    "    'Total de Recomendacoes': 'ttl_rec',\n",
    "    'Total de Aeronaves Envolvidas': 'ttl_aer_env',\n",
    "    'Ocorrencia na Saida da Pista?': 'sai_pst',\n",
    "    'Tipo de Ocorrencia': 'tpo_ocr',\n",
    "    'Matricula da Aeronave': 'mat_aer',\n",
    "    'Tipo de Aeronave': 'tpo_aer',\n",
    "    'Fabricante da Aeronave': 'fab_aer',\n",
    "    'Modelo de Aeronave': 'mdl_aer',\n",
    "    'Aeronave Motor Tipo': 'tpo_mtr',\n",
    "    'Quantidade de Assentos na Aeronave': 'qtd_ase_aer',\n",
    "    'Ano de Fabricacao da Aeronave': 'ano_fab_aer',\n",
    "    'Voo de Origem do Acidente': 'voo_ori',\n",
    "    'Voo Destino do Acidente': 'voo_dst',\n",
    "    'Fase de Operacao da Aeronave': 'fse_ope',\n",
    "    'Nivel de Dano da Aeronave': 'nvl_dno',\n",
    "    'Total de Fatalidades no Acidente': 'ttl_fat'\n",
    "}\n",
    "\n",
    "df_silver = df_silver.rename(columns=mapa_colunas)\n",
    "\n",
    "# --- 3.2 LIMPEZA DE TEXTO (Strings) ---\n",
    "cols_text = ['mun', 'uf', 'cls_ocr', 'tpo_ocr', 'mat_aer', 'tpo_aer', 'fab_aer', 'mdl_aer', 'fse_ope', 'nvl_dno']\n",
    "\n",
    "for col in cols_text:\n",
    "    if col in df_silver.columns:\n",
    "        df_silver[col] = df_silver[col].str.strip()\n",
    "        df_silver[col] = df_silver[col].replace(['****', '***', ''], np.nan)\n",
    "        df_silver[col] = df_silver[col].fillna(\"N√ÉO INFORMADO\")\n",
    "\n",
    "# --- 3.3 TRATAMENTO DE DATAS ---\n",
    "print(\"   -> Processando datas...\")\n",
    "df_silver['dta_ocr'] = pd.to_datetime(df_silver['dta_ocr'], format='%d/%m/%Y %H:%M', errors='coerce')\n",
    "df_silver['dta_ocr'] = df_silver['dta_ocr'].fillna(pd.Timestamp('1900-01-01 00:00:00'))\n",
    "\n",
    "df_silver['ano'] = df_silver['dta_ocr'].dt.year\n",
    "df_silver['mes'] = df_silver['dta_ocr'].dt.month\n",
    "df_silver['dia'] = df_silver['dta_ocr'].dt.day\n",
    "df_silver['hor'] = df_silver['dta_ocr'].dt.hour\n",
    "\n",
    "# --- 3.4 TRATAMENTO DE COORDENADAS ---\n",
    "print(\"   -> Corrigindo Lat/Lon cient√≠fica...\")\n",
    "\n",
    "def limpar_coord(valor):\n",
    "    if pd.isna(valor) or valor == '': return 0.0\n",
    "    try:\n",
    "        val_str = str(valor).replace(',', '.')\n",
    "        val_float = float(val_str)\n",
    "        if abs(val_float) > 180: return 0.0\n",
    "        return val_float\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "if 'lat' in df_silver.columns: df_silver['lat'] = df_silver['lat'].apply(limpar_coord)\n",
    "if 'lon' in df_silver.columns: df_silver['lon'] = df_silver['lon'].apply(limpar_coord)\n",
    "\n",
    "# --- 3.5 TRATAMENTO NUM√âRICO ---\n",
    "print(\"   -> Convertendo n√∫meros...\")\n",
    "cols_int = ['ttl_fat', 'ttl_rec', 'ttl_aer_env', 'ano_fab_aer', 'qtd_ase_aer']\n",
    "\n",
    "for col in cols_int:\n",
    "    if col in df_silver.columns:\n",
    "        df_silver[col] = pd.to_numeric(df_silver[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# --- 3.6 SEVERIDADE ---\n",
    "def calcular_severidade(fatais):\n",
    "    if fatais == 0: return 'LEVE'\n",
    "    elif fatais <= 10: return 'MODERADA'\n",
    "    elif fatais <= 50: return 'GRAVE'\n",
    "    else: return 'CRITICA'\n",
    "\n",
    "df_silver['nvl_sev'] = df_silver['ttl_fat'].apply(calcular_severidade)\n",
    "\n",
    "# --- 3.7 SELE√á√ÉO FINAL ---\n",
    "cols_finais = [\n",
    "    'cod_ocr', 'dta_ocr', 'ano', 'mes', 'dia', 'hor', \n",
    "    'uf', 'mun', 'lat', 'lon', \n",
    "    'cls_ocr', 'tpo_ocr', 'fse_ope', \n",
    "    'tpo_aer', 'fab_aer', 'mdl_aer', 'mat_aer', 'ano_fab_aer', 'qtd_ase_aer',\n",
    "    'nvl_dno', 'ttl_fat', 'ttl_rec', 'nvl_sev'\n",
    "]\n",
    "cols_existentes = [c for c in cols_finais if c in df_silver.columns]\n",
    "df_final = df_silver[cols_existentes].copy()\n",
    "\n",
    "print(f\"‚ú® Transforma√ß√£o conclu√≠da! Base Silver Final: {len(df_final)} registros.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. CARGA NO BANCO DE DADOS (LOADING)\n",
    "# ==============================================================================\n",
    "print(\"\\nüîå Conectando ao Banco de Dados...\")\n",
    "\n",
    "# --- CONFIGURA√á√ÉO ATUALIZADA (DOCKER) ---\n",
    "# Se o script roda no Container 'jupyter-lab', o host do banco √© o nome do servi√ßo 'db'\n",
    "jdbc_hostname = \"db\"            \n",
    "jdbc_port     = \"5432\"\n",
    "jdbc_database = \"acidentes_db\"  \n",
    "db_user       = \"postgres\"\n",
    "db_password   = \"admin\"\n",
    "\n",
    "# URL de Conex√£o\n",
    "db_url = f\"postgresql+psycopg2://{db_user}:{db_password}@{jdbc_hostname}:{jdbc_port}/{jdbc_database}\"\n",
    "\n",
    "# 4.1 Cria√ß√£o da Engine\n",
    "engine = None\n",
    "try:\n",
    "    engine = create_engine(db_url)\n",
    "    with engine.connect() as conn:\n",
    "        pass \n",
    "    print(f\"‚úÖ Conectado com sucesso ao Host: {jdbc_hostname} | DB: {jdbc_database}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Falha ao conectar em '{jdbc_hostname}'. Tentando 'localhost' (caso esteja rodando localmente)...\")\n",
    "    try:\n",
    "        # Fallback para localhost se voc√™ rodar fora do Docker\n",
    "        db_url_local = f\"postgresql+psycopg2://{db_user}:{db_password}@localhost:5432/{jdbc_database}\"\n",
    "        engine = create_engine(db_url_local)\n",
    "        with engine.connect() as conn:\n",
    "            pass\n",
    "        print(\"‚úÖ Conectado via Localhost!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"‚ùå Erro fatal de conex√£o: {e2}\")\n",
    "        exit(1)\n",
    "\n",
    "# 4.2 EXECU√á√ÉO DO DDL\n",
    "print(\"üìú Verificando DDL...\")\n",
    "possible_ddl_paths = [\n",
    "    \"ddl.sql\",\n",
    "    os.path.join(\"Data_Layer\", \"silver\", \"ddl.sql\"),\n",
    "    os.path.join(\"silver\", \"ddl.sql\")\n",
    "]\n",
    "\n",
    "for path in possible_ddl_paths:\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            with open(path, 'r') as file:\n",
    "                ddl_content = file.read()\n",
    "            with engine.connect() as conn:\n",
    "                conn.execute(text(ddl_content))\n",
    "                conn.commit()\n",
    "            print(f\"‚úÖ DDL executado: {path}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Erro no DDL: {e}\")\n",
    "\n",
    "# 4.3 INSER√á√ÉO\n",
    "try:\n",
    "    print(f\"üíæ Inserindo {len(df_final)} registros na tabela 'public.acd'...\")\n",
    "    \n",
    "    df_final.to_sql(\n",
    "        name='acd',         \n",
    "        schema='public',    \n",
    "        con=engine,\n",
    "        if_exists='replace', \n",
    "        index=False,\n",
    "        chunksize=1000,\n",
    "        method='multi'\n",
    "    )\n",
    "    print(\"‚úÖ SUCESSO! Dados carregados na tabela 'public.acd'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro na inser√ß√£o: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"\\nüöÄ Job ETL finalizado em {time.time() - start_time:.2f} segundos!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
