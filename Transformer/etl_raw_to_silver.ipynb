{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a16438b",
   "metadata": {},
   "source": [
    "### Se√ß√£o 1: Importa√ß√µes de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f7ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, when, to_timestamp, year, month, dayofmonth, hour\n",
    "from pyspark.sql.types import IntegerType, StringType, TimestampType\n",
    "import os\n",
    "import time\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b74585d",
   "metadata": {},
   "source": [
    "### Se√ß√£o 2: Inicializa√ß√£o da Sess√£o Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16187a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Iniciando a sess√£o Spark...\")\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Acidentes_Aereos_ETL_Raw_to_Silver\") \\\n",
    "    .getOrCreate()\n",
    "print(\"Sess√£o Spark iniciada com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b8381f",
   "metadata": {},
   "source": [
    "### Se√ß√£o 3: Defini√ß√£o de Caminhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebc8997",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = \"../Data_Layer/raw\"\n",
    "print(f\"Lendo arquivos da origem (RAW) de: {raw_path}\")\n",
    "\n",
    "print(\"Lendo arquivo da camada RAW...\")\n",
    "try:\n",
    "    df_raw = spark.read.option(\"header\", \"true\").option(\"sep\", \";\").option(\"encoding\", \"UTF-8\").csv(os.path.join(raw_path, \"data_raw.csv\"))\n",
    "    print(\"Arquivo RAW carregado com sucesso!\")\n",
    "    print(f\"Total de registros: {df_raw.count()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler o arquivo CSV. Verifique o caminho e a permiss√£o dos arquivos. Erro: {e}\")\n",
    "    spark.stop()\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee820e",
   "metadata": {},
   "source": [
    "### Se√ß√£o 4: Leitura dos Dados Brutos (RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c98097",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Visualizando estrutura dos dados RAW...\")\n",
    "df_raw.printSchema()\n",
    "print(\"\\nPrimeiras 5 linhas:\")\n",
    "df_raw.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0026a4",
   "metadata": {},
   "source": [
    "### Se√ß√£o 5: Transforma√ß√£o e Unifica√ß√£o dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c89061",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Iniciando a transforma√ß√£o e limpeza dos dados...\")\n",
    "\n",
    "# 1. Remover espa√ßos em branco das colunas\n",
    "print(\"1Ô∏è‚É£  Removendo espa√ßos em branco dos nomes das colunas...\")\n",
    "for old_col in df_raw.columns:\n",
    "    new_col = old_col.strip()\n",
    "    df_raw = df_raw.withColumnRenamed(old_col, new_col)\n",
    "print(\"   ‚úÖ Colunas padronizadas\")\n",
    "\n",
    "# 2. Converter coluna de data e hora\n",
    "print(\"\\n2Ô∏è‚É£  Convertendo data e hora da ocorr√™ncia...\")\n",
    "df_silver = df_raw.withColumn(\n",
    "    \"Data e Hora da Ocorrencia\",\n",
    "    to_timestamp(col(\"Data e Hora da Ocorrencia\"), \"dd/MM/yyyy HH:mm\")\n",
    ")\n",
    "print(\"   ‚úÖ Data convertida para TimestampType\")\n",
    "\n",
    "# 3. Extrair componentes de data\n",
    "print(\"\\n3Ô∏è‚É£  Extraindo componentes de data (Ano, M√™s, Dia, Hora)...\")\n",
    "df_silver = df_silver.withColumn(\"Ano\", year(col(\"Data e Hora da Ocorrencia\")))\n",
    "df_silver = df_silver.withColumn(\"Mes\", month(col(\"Data e Hora da Ocorrencia\")))\n",
    "df_silver = df_silver.withColumn(\"Dia\", dayofmonth(col(\"Data e Hora da Ocorrencia\")))\n",
    "df_silver = df_silver.withColumn(\"Hora\", hour(col(\"Data e Hora da Ocorrencia\")))\n",
    "print(\"   ‚úÖ Componentes de data extra√≠dos\")\n",
    "\n",
    "# 4. Converter colunas num√©ricas\n",
    "print(\"\\n4Ô∏è‚É£  Convertendo colunas num√©ricas...\")\n",
    "numeric_cols = [\n",
    "    \"Total de Fatalidades no Acidente\",\n",
    "    \"Total de Recomendacoes\",\n",
    "    \"Total de Aeronaves Envolvidas\",\n",
    "    \"Quantidade de Assentos na Aeronave\",\n",
    "    \"Ano de Fabricacao da Aeronave\"\n",
    "]\n",
    "\n",
    "for col_name in numeric_cols:\n",
    "    if col_name in df_silver.columns:\n",
    "        df_silver = df_silver.withColumn(col_name, col(col_name).cast(IntegerType()))\n",
    "\n",
    "print(f\"   ‚úÖ {len([c for c in numeric_cols if c in df_silver.columns])} colunas convertidas para IntegerType\")\n",
    "\n",
    "# 5. Preencher valores nulos com 0 nas colunas num√©ricas\n",
    "print(\"\\n5Ô∏è‚É£  Preenchendo valores nulos com 0...\")\n",
    "for col_name in numeric_cols:\n",
    "    if col_name in df_silver.columns:\n",
    "        df_silver = df_silver.fillna({col_name: 0})\n",
    "        \n",
    "print(\"   ‚úÖ Valores nulos preenchidos\")\n",
    "\n",
    "# 6. Criar indicador de severidade\n",
    "print(\"\\n6Ô∏è‚É£  Criando indicador de severidade...\")\n",
    "df_silver = df_silver.withColumn(\n",
    "    \"Nivel_Severidade\",\n",
    "    when(col(\"Total de Fatalidades no Acidente\") > 50, \"CR√çTICO\")\n",
    "    .when(col(\"Total de Fatalidades no Acidente\") > 10, \"GRAVE\")\n",
    "    .when(col(\"Total de Fatalidades no Acidente\") > 0, \"MODERADO\")\n",
    "    .otherwise(\"LEVE\")\n",
    ")\n",
    "print(\"   ‚úÖ Indicador 'Nivel_Severidade' criado\")\n",
    "\n",
    "# 7. Filtrar registros com data v√°lida (opcional)\n",
    "print(\"\\n7Ô∏è‚É£  Filtrando registros com data v√°lida...\")\n",
    "df_silver = df_silver.filter(col(\"Data e Hora da Ocorrencia\").isNotNull())\n",
    "print(f\"   ‚úÖ Registros ap√≥s filtragem: {df_silver.count()}\")\n",
    "\n",
    "print(\"\\n‚úÖ Transforma√ß√£o de dados conclu√≠da!\")\n",
    "df_silver.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46056d7",
   "metadata": {},
   "source": [
    "### Se√ß√£o 6: Carga dos Dados no Banco de Dados PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57679597",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nIniciando a carga de dados no banco de dados...\")\n",
    "jdbc_hostname = os.getenv(\"DB_HOST\", \"localhost\")\n",
    "jdbc_port     = os.getenv(\"DB_PORT\", \"5432\")\n",
    "jdbc_database = os.getenv(\"DB_NAME\", \"acidentes_aereos\")\n",
    "db_user       = os.getenv(\"DB_USER\", \"postgres\")\n",
    "db_password   = os.getenv(\"DB_PASSWORD\", \"postgres\")\n",
    "table_name    = \"public.acidentes_silver\"\n",
    "jdbc_url = f\"jdbc:postgresql://{jdbc_hostname}:{jdbc_port}/{jdbc_database}\"\n",
    "connection_properties = {\"user\": db_user, \"password\": db_password, \"driver\": \"org.postgresql.Driver\"}\n",
    "\n",
    "retries = 10\n",
    "wait_seconds = 5\n",
    "for i in range(retries):\n",
    "    try:\n",
    "        print(\"Tentando conectar ao banco de dados...\")\n",
    "        conn = psycopg2.connect(host=jdbc_hostname, dbname=jdbc_database, user=db_user, password=db_password, port=jdbc_port)\n",
    "        conn.close()\n",
    "        print(\"‚úÖ Conex√£o com o banco de dados bem-sucedida!\")\n",
    "        break\n",
    "    except psycopg2.OperationalError as e:\n",
    "        print(f\"‚è≥ Banco de dados n√£o est√° pronto. Tentando novamente em {wait_seconds} segundos...\")\n",
    "        time.sleep(wait_seconds)\n",
    "        if i == retries - 1:\n",
    "            print(\"‚ùå N√£o foi poss√≠vel conectar ao banco de dados. Abortando.\")\n",
    "            spark.stop()\n",
    "            raise e\n",
    "\n",
    "try:\n",
    "    print(f\"Iniciando a escrita de dados na tabela: {table_name}\")\n",
    "    \n",
    "    df_silver.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .jdbc(url=jdbc_url, table=table_name, properties=connection_properties)\n",
    "        \n",
    "    print(f\"‚úÖ Tabela '{table_name}' populada com sucesso no banco de dados '{jdbc_database}'!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Ocorreu um erro ao salvar no banco de dados: {e}\")\n",
    "    spark.stop()\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce80f000",
   "metadata": {},
   "source": [
    "### Se√ß√£o 7: Valida√ß√£o e Finaliza√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b35e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nValidando a tabela SILVER (amostra):\")\n",
    "df_silver.orderBy(col(\"Ano\").desc()).show(10, truncate=False)\n",
    "\n",
    "print(\"\\n=== ESTAT√çSTICAS FINAIS ===\")\n",
    "print(f\"Total de registros processados: {df_silver.count()}\")\n",
    "print(f\"Colunas na tabela SILVER: {len(df_silver.columns)}\")\n",
    "\n",
    "print(\"\\nDistribui√ß√£o por N√≠vel de Severidade:\")\n",
    "df_silver.groupBy(\"Nivel_Severidade\").count().orderBy(col(\"count\").desc()).show()\n",
    "\n",
    "print(\"\\nüöÄ Job ETL (Raw ‚Üí Silver ‚Üí Database) finalizado com sucesso!\")\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
